
#拼接纠正实例:

#P(我们猜测他想输入的单词 | 他实际输入的单词)
#设 D = 他实际输入的单词
#设 h小i = 我们的猜测

#P(h | D) = P(h) * P(D | h) / P(D)
#P(h) 先验概率
#P(D) 因为是实际输入单词,是个常数,可以约掉
#所以可以化简:P(h | D) = P(h) * P(D | h)

#最大似然:最符合观测数据的(即P(D | h)最大的)最有优势
#奥卡姆剃刀:P(h)较大的模型有较大的优势


#垃圾邮件过滤
#D表示这封邮件,D由N个单词组成,我们用h+来表示垃圾邮件,h-表示正常邮件
#D = d1 + d2 + ... dn
#P(h+ | D) = P(h+) * P(D | h+) / P(D)
#P(h- | D) = P(h-) * P(D | h-) / P(D)

#朴素贝叶斯假设特征之间是独立,互不影响的
#P(D | h+) = P(d1, d2, ..,dn | h+)
#对上式再进行展开:P(d1 | h+) * P(d2 | d1, h+) * P(d3 | d2, d1, h+) *..
#根据朴素贝叶斯理论,可以化简成:P(d1 | h+) * P(d2 | h+) * P(d3 | h+)..
#那么对于这个问题,只要统计di这个单词在垃圾邮件中出现的频率即可